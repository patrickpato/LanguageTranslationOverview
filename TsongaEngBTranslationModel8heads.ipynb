{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz5SV6xglFoR",
        "outputId": "86c08f6d-729a-4a0b-d9c9-7a39283e2873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKLIAewBmaLG",
        "outputId": "f2826299-7c07-4355-8ab9-6c6a51112a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-pil\n",
            "E: Unable to locate package python-lxml\n"
          ]
        }
      ],
      "source": [
        "!apt-get -y install protobuf-compiler python-pil python-lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XybjHkhnmcQ0",
        "outputId": "43e43e6b-fa26-40ef-b2df-f64d27339e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openNMT-py\n",
            "  Downloading OpenNMT_py-3.5.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting torch<2.3,>=2.1 (from openNMT-py)\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting configargparse (from openNMT-py)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ctranslate2<5,>=4 (from openNMT-py)\n",
            "  Downloading ctranslate2-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (2.17.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (2.2.5)\n",
            "Collecting waitress (from openNMT-py)\n",
            "  Downloading waitress-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pyonmttok<2,>=1.37 (from openNMT-py)\n",
            "  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (6.0.1)\n",
            "Collecting sacrebleu (from openNMT-py)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from openNMT-py)\n",
            "  Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting pyahocorasick (from openNMT-py)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\n",
            "Collecting fasttext-wheel (from openNMT-py)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (3.7.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4->openNMT-py) (71.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4->openNMT-py) (1.26.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->openNMT-py) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->openNMT-py) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->openNMT-py) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->openNMT-py) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->openNMT-py) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->openNMT-py) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3,>=2.1->openNMT-py)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->openNMT-py)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->openNMT-py)\n",
            "  Downloading pybind11-2.13.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->openNMT-py) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->openNMT-py) (8.1.7)\n",
            "Collecting portalocker (from sacrebleu->openNMT-py)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->openNMT-py) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->openNMT-py) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->openNMT-py)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->openNMT-py) (4.9.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.3,>=2.1->openNMT-py) (2.1.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->openNMT-py) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->openNMT-py) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->openNMT-py) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->openNMT-py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->openNMT-py) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->openNMT-py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->openNMT-py) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->openNMT-py) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->openNMT-py) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->openNMT-py) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->openNMT-py) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->openNMT-py) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->openNMT-py) (7.0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.3,>=2.1->openNMT-py) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->openNMT-py) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->openNMT-py) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->openNMT-py) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->openNMT-py) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->openNMT-py) (0.1.2)\n",
            "Downloading OpenNMT_py-3.5.1-py3-none-any.whl (262 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.8/262.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (192.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.3/192.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading waitress-3.0.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.1-py3-none-any.whl (238 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.8/238.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: waitress, triton, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ctranslate2, configargparse, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, fasttext-wheel, nvidia-cusolver-cu12, torch, openNMT-py\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 configargparse-1.7 ctranslate2-4.3.1 fasttext-wheel-0.9.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openNMT-py-3.5.1 portalocker-2.10.1 pyahocorasick-2.1.0 pybind11-2.13.1 pyonmttok-1.37.1 rapidfuzz-3.9.6 sacrebleu-2.4.2 torch-2.2.2 triton-2.2.0 waitress-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openNMT-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvU6TpXBmeiw"
      },
      "outputs": [],
      "source": [
        "config = '''# config.yaml\n",
        "\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "# Training files\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Tsonga_Tsonga_Parralel_train.txt.subword\n",
        "        path_tgt: /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Tsonga_English_Parralel_train.txt.subword\n",
        "        transforms: [filtertoolong]\n",
        "    valid:\n",
        "        path_src: /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Tsonga_Tsonga_dev.txt.subword\n",
        "        path_tgt: /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Tsonga_English_dev.txt.subword\n",
        "        transforms: [filtertoolong]\n",
        "\n",
        "# Vocabulary files, generated by onmt_build_vocab\n",
        "src_vocab: run/source.vocab\n",
        "tgt_vocab: run/target.vocab\n",
        "\n",
        "# Vocabulary size - should be the same as in sentence piece\n",
        "src_vocab_size: 50000\n",
        "tgt_vocab_size: 50000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 64\n",
        "tgt_seq_length: 64\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/source.model\n",
        "tgt_subword_model: /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/target.model\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/model.tsongaeng\n",
        "\n",
        "# Stop training if it does not imporve after n validations\n",
        "early_stopping: 10\n",
        "\n",
        "# Default: 5000 - Save a model checkpoint for each n\n",
        "save_checkpoint_steps: 1000\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "# keep_checkpoint: 3\n",
        "\n",
        "seed: 2023\n",
        "\n",
        "# Default: 100000 - Train the model to max n steps\n",
        "# Increase to 200000 or more for large datasets\n",
        "# For fine-tuning, add up the required steps to the original steps\n",
        "train_steps: 6000\n",
        "\n",
        "# Default: 10000 - Run validation after n steps\n",
        "valid_steps: 4000\n",
        "\n",
        "# Default: 4000 - for large datasets, try up to 8000\n",
        "warmup_steps: 5000\n",
        "report_every: 100\n",
        "\n",
        "# Number of GPUs, and IDs of GPUs\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Batching\n",
        "bucket_size: 262144\n",
        "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 1024  # Tokens per batch, change when CUDA out of memory\n",
        "valid_batch_size: 1024\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 0.4\n",
        "# warmup_steps: 8000\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 8\n",
        "dec_layers: 8\n",
        "heads: 8\n",
        "hidden_size: 1024\n",
        "word_vec_size: 1024\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "'''\n",
        "\n",
        "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1W1IdoOnx7Z",
        "outputId": "8d5890d9-f24a-4340-b43b-cbbe16cdaa3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2024-08-08 09:13:00,414 INFO] Counter vocab from -1 samples.\n",
            "[2024-08-08 09:13:00,414 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2024-08-08 09:13:05,173 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=708)\n",
            "\n",
            "[2024-08-08 09:13:05,189 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=683)\n",
            "\n",
            "[2024-08-08 09:13:05,253 INFO] Counters src: 30033\n",
            "[2024-08-08 09:13:05,253 INFO] Counters tgt: 26931\n"
          ]
        }
      ],
      "source": [
        "!onmt_build_vocab -config /content/config.yaml -n_sample -1 -num_threads 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM-gLJr-nzGG",
        "outputId": "59d3c988-bdea-4c8b-957e-6ccba326a30e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-08 09:13:08,856 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2024-08-08 09:13:08,856 INFO] Parsed 2 corpora from -data.\n",
            "[2024-08-08 09:13:08,856 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2024-08-08 09:13:09,088 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '▁ku', '▁.', '▁ya', '▁na', '▁wa', '▁hi']\n",
            "[2024-08-08 09:13:09,088 INFO] The decoder start token is: <s>\n",
            "[2024-08-08 09:13:09,088 INFO] Building model...\n",
            "[2024-08-08 09:13:12,030 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2024-08-08 09:13:12,030 INFO] Non quantized layer compute is fp16\n",
            "[2024-08-08 09:13:12,429 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(30040, 1024, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-7): 8 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=1024, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(26936, 1024, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-7): 8 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=1024, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=1024, out_features=26936, bias=True)\n",
            ")\n",
            "[2024-08-08 09:13:12,433 INFO] encoder: 97904640\n",
            "[2024-08-08 09:13:12,433 INFO] decoder: 155906360\n",
            "[2024-08-08 09:13:12,433 INFO] * number of parameters: 253811000\n",
            "[2024-08-08 09:13:12,434 INFO] Trainable parameters = {'torch.float32': 253811000, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2024-08-08 09:13:12,434 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2024-08-08 09:13:12,434 INFO]  * src vocab size = 30040\n",
            "[2024-08-08 09:13:12,435 INFO]  * tgt vocab size = 26936\n",
            "[2024-08-08 09:13:12,750 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2024-08-08 09:13:12,750 INFO] Starting training on GPU: [0]\n",
            "[2024-08-08 09:13:12,750 INFO] Start training loop and validate every 4000 steps...\n",
            "[2024-08-08 09:13:12,750 INFO] Scoring with: ['filtertoolong']\n",
            "[2024-08-08 09:13:54,907 INFO] Step 100/ 6000; acc: 6.3; ppl: 17673.4; xent: 9.8; lr: 0.00000; sents:   29970; bsz:  904/ 827/75; 8576/7845 tok/s;     42 sec;\n",
            "[2024-08-08 09:14:21,710 INFO] Step 200/ 6000; acc: 9.0; ppl: 7400.1; xent: 8.9; lr: 0.00001; sents:   30616; bsz:  912/ 848/77; 13606/12653 tok/s;     69 sec;\n",
            "[2024-08-08 09:14:48,302 INFO] Step 300/ 6000; acc: 9.3; ppl: 3673.3; xent: 8.2; lr: 0.00001; sents:   29350; bsz:  909/ 815/73; 13671/12267 tok/s;     96 sec;\n",
            "[2024-08-08 09:15:15,153 INFO] Step 400/ 6000; acc: 14.6; ppl: 1585.4; xent: 7.4; lr: 0.00001; sents:   32317; bsz:  897/ 834/81; 13360/12419 tok/s;    122 sec;\n",
            "[2024-08-08 09:15:36,908 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=1174)\n",
            "\n",
            "[2024-08-08 09:15:36,908 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2024-08-08 09:15:59,633 INFO] Step 500/ 6000; acc: 16.4; ppl: 1001.3; xent: 6.9; lr: 0.00002; sents:   31162; bsz:  905/ 839/78; 8142/7547 tok/s;    167 sec;\n",
            "[2024-08-08 09:16:26,623 INFO] Step 600/ 6000; acc: 17.5; ppl: 821.1; xent: 6.7; lr: 0.00002; sents:   29316; bsz:  911/ 837/73; 13507/12405 tok/s;    194 sec;\n",
            "[2024-08-08 09:16:53,476 INFO] Step 700/ 6000; acc: 19.7; ppl: 703.5; xent: 6.6; lr: 0.00002; sents:   30032; bsz:  899/ 832/75; 13395/12392 tok/s;    221 sec;\n",
            "[2024-08-08 09:17:20,555 INFO] Step 800/ 6000; acc: 21.5; ppl: 589.1; xent: 6.4; lr: 0.00003; sents:   30368; bsz:  906/ 833/76; 13386/12300 tok/s;    248 sec;\n",
            "[2024-08-08 09:17:47,842 INFO] Step 900/ 6000; acc: 23.1; ppl: 494.9; xent: 6.2; lr: 0.00003; sents:   29907; bsz:  913/ 831/75; 13381/12183 tok/s;    275 sec;\n",
            "[2024-08-08 09:18:07,315 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=1157)\n",
            "\n",
            "[2024-08-08 09:18:07,315 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2024-08-08 09:18:36,332 INFO] Step 1000/ 6000; acc: 25.7; ppl: 404.5; xent: 6.0; lr: 0.00004; sents:   32377; bsz:  906/ 841/81; 7471/6937 tok/s;    324 sec;\n",
            "[2024-08-08 09:18:36,343 INFO] Saving checkpoint models/model.tsongaeng_step_1000.pt\n",
            "[2024-08-08 09:19:11,250 INFO] Step 1100/ 6000; acc: 27.4; ppl: 340.6; xent: 5.8; lr: 0.00004; sents:   30785; bsz:  907/ 835/77; 10386/9563 tok/s;    358 sec;\n",
            "[2024-08-08 09:19:38,342 INFO] Step 1200/ 6000; acc: 29.0; ppl: 290.5; xent: 5.7; lr: 0.00004; sents:   30519; bsz:  910/ 839/76; 13432/12393 tok/s;    386 sec;\n",
            "[2024-08-08 09:20:05,602 INFO] Step 1300/ 6000; acc: 30.4; ppl: 255.6; xent: 5.5; lr: 0.00005; sents:   30990; bsz:  906/ 826/77; 13293/12121 tok/s;    413 sec;\n",
            "[2024-08-08 09:20:32,711 INFO] Step 1400/ 6000; acc: 32.0; ppl: 221.5; xent: 5.4; lr: 0.00005; sents:   30183; bsz:  899/ 828/75; 13265/12217 tok/s;    440 sec;\n",
            "[2024-08-08 09:20:47,020 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=1141)\n",
            "\n",
            "[2024-08-08 09:20:47,021 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2024-08-08 09:21:19,244 INFO] Step 1500/ 6000; acc: 34.6; ppl: 182.5; xent: 5.2; lr: 0.00005; sents:   30355; bsz:  903/ 840/76; 7760/7223 tok/s;    486 sec;\n",
            "[2024-08-08 09:21:46,274 INFO] Step 1600/ 6000; acc: 36.3; ppl: 157.5; xent: 5.1; lr: 0.00006; sents:   29691; bsz:  908/ 828/74; 13443/12256 tok/s;    514 sec;\n",
            "[2024-08-08 09:22:13,378 INFO] Step 1700/ 6000; acc: 38.5; ppl: 133.7; xent: 4.9; lr: 0.00006; sents:   30358; bsz:  917/ 835/76; 13537/12327 tok/s;    541 sec;\n",
            "[2024-08-08 09:22:40,535 INFO] Step 1800/ 6000; acc: 40.3; ppl: 118.5; xent: 4.8; lr: 0.00006; sents:   31006; bsz:  910/ 836/78; 13410/12313 tok/s;    568 sec;\n",
            "[2024-08-08 09:23:07,721 INFO] Step 1900/ 6000; acc: 42.3; ppl: 102.7; xent: 4.6; lr: 0.00007; sents:   31043; bsz:  901/ 831/78; 13257/12233 tok/s;    595 sec;\n",
            "[2024-08-08 09:23:19,961 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=1159)\n",
            "\n",
            "[2024-08-08 09:23:19,961 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2024-08-08 09:23:56,837 INFO] Step 2000/ 6000; acc: 45.1; ppl:  83.3; xent: 4.4; lr: 0.00007; sents:   31872; bsz:  898/ 831/80; 7316/6771 tok/s;    644 sec;\n",
            "[2024-08-08 09:23:56,850 INFO] Saving checkpoint models/model.tsongaeng_step_2000.pt\n",
            "[2024-08-08 09:24:31,208 INFO] Step 2100/ 6000; acc: 46.2; ppl:  74.4; xent: 4.3; lr: 0.00007; sents:   28353; bsz:  912/ 835/71; 10616/9718 tok/s;    678 sec;\n",
            "[2024-08-08 09:24:58,578 INFO] Step 2200/ 6000; acc: 47.7; ppl:  69.5; xent: 4.2; lr: 0.00008; sents:   32838; bsz:  901/ 827/82; 13172/12086 tok/s;    706 sec;\n",
            "[2024-08-08 09:25:25,869 INFO] Step 2300/ 6000; acc: 49.3; ppl:  60.8; xent: 4.1; lr: 0.00008; sents:   31708; bsz:  908/ 834/79; 13304/12224 tok/s;    733 sec;\n",
            "[2024-08-08 09:26:12,674 INFO] Step 2400/ 6000; acc: 50.4; ppl:  54.6; xent: 4.0; lr: 0.00008; sents:   28527; bsz:  903/ 834/71; 7721/7129 tok/s;    780 sec;\n",
            "[2024-08-08 09:26:39,843 INFO] Step 2500/ 6000; acc: 53.3; ppl:  45.3; xent: 3.8; lr: 0.00009; sents:   29998; bsz:  916/ 834/75; 13485/12278 tok/s;    807 sec;\n",
            "[2024-08-08 09:27:06,829 INFO] Step 2600/ 6000; acc: 53.8; ppl:  43.2; xent: 3.8; lr: 0.00009; sents:   28992; bsz:  911/ 841/72; 13497/12463 tok/s;    834 sec;\n",
            "[2024-08-08 09:27:34,006 INFO] Step 2700/ 6000; acc: 55.8; ppl:  39.1; xent: 3.7; lr: 0.00010; sents:   31923; bsz:  898/ 821/80; 13212/12088 tok/s;    861 sec;\n",
            "[2024-08-08 09:28:01,316 INFO] Step 2800/ 6000; acc: 56.6; ppl:  36.3; xent: 3.6; lr: 0.00010; sents:   30728; bsz:  904/ 836/77; 13247/12247 tok/s;    889 sec;\n",
            "[2024-08-08 09:28:22,221 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2316)\n",
            "\n",
            "[2024-08-08 09:28:22,221 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2024-08-08 09:28:51,141 INFO] Step 2900/ 6000; acc: 58.3; ppl:  32.5; xent: 3.5; lr: 0.00010; sents:   31253; bsz:  905/ 834/78; 7266/6693 tok/s;    938 sec;\n",
            "[2024-08-08 09:29:18,406 INFO] Step 3000/ 6000; acc: 59.4; ppl:  30.1; xent: 3.4; lr: 0.00011; sents:   31593; bsz:  910/ 825/79; 13357/12110 tok/s;    966 sec;\n",
            "[2024-08-08 09:29:18,418 INFO] Saving checkpoint models/model.tsongaeng_step_3000.pt\n",
            "[2024-08-08 09:29:53,270 INFO] Step 3100/ 6000; acc: 60.1; ppl:  28.5; xent: 3.4; lr: 0.00011; sents:   32500; bsz:  890/ 834/81; 10216/9567 tok/s;   1001 sec;\n",
            "[2024-08-08 09:30:20,453 INFO] Step 3200/ 6000; acc: 61.1; ppl:  26.6; xent: 3.3; lr: 0.00011; sents:   30055; bsz:  912/ 840/75; 13414/12363 tok/s;   1028 sec;\n",
            "[2024-08-08 09:30:47,469 INFO] Step 3300/ 6000; acc: 60.9; ppl:  26.8; xent: 3.3; lr: 0.00012; sents:   28737; bsz:  909/ 827/72; 13457/12243 tok/s;   1055 sec;\n",
            "[2024-08-08 09:31:03,676 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=1178)\n",
            "\n",
            "[2024-08-08 09:31:03,676 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2024-08-08 09:31:37,638 INFO] Step 3400/ 6000; acc: 63.0; ppl:  23.4; xent: 3.2; lr: 0.00012; sents:   28877; bsz:  907/ 839/72; 7231/6686 tok/s;   1105 sec;\n",
            "[2024-08-08 09:32:04,746 INFO] Step 3500/ 6000; acc: 64.2; ppl:  21.4; xent: 3.1; lr: 0.00012; sents:   28308; bsz:  924/ 834/71; 13632/12302 tok/s;   1132 sec;\n",
            "[2024-08-08 09:32:31,932 INFO] Step 3600/ 6000; acc: 64.7; ppl:  20.9; xent: 3.0; lr: 0.00013; sents:   30802; bsz:  900/ 842/77; 13247/12389 tok/s;   1159 sec;\n",
            "[2024-08-08 09:32:59,275 INFO] Step 3700/ 6000; acc: 64.3; ppl:  21.6; xent: 3.1; lr: 0.00013; sents:   31362; bsz:  894/ 834/78; 13086/12198 tok/s;   1187 sec;\n",
            "[2024-08-08 09:33:26,427 INFO] Step 3800/ 6000; acc: 66.0; ppl:  19.4; xent: 3.0; lr: 0.00013; sents:   30348; bsz:  919/ 825/76; 13537/12148 tok/s;   1214 sec;\n",
            "[2024-08-08 09:33:35,368 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=1157)\n",
            "\n",
            "[2024-08-08 09:33:35,369 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2024-08-08 09:34:14,107 INFO] Step 3900/ 6000; acc: 67.5; ppl:  18.0; xent: 2.9; lr: 0.00014; sents:   32768; bsz:  890/ 830/82; 7470/6967 tok/s;   1261 sec;\n",
            "[2024-08-08 09:34:41,275 INFO] Step 4000/ 6000; acc: 68.2; ppl:  16.8; xent: 2.8; lr: 0.00014; sents:   30211; bsz:  911/ 841/76; 13417/12377 tok/s;   1289 sec;\n",
            "[2024-08-08 09:35:38,941 INFO] valid stats calculation\n",
            "                           took: 57.664384841918945 s.\n",
            "[2024-08-08 09:35:38,943 INFO] Train perplexity: 126.933\n",
            "[2024-08-08 09:35:38,943 INFO] Train accuracy: 42.2519\n",
            "[2024-08-08 09:35:38,944 INFO] Sentences processed: 1.2221e+06\n",
            "[2024-08-08 09:35:38,944 INFO] Average bsz:  906/ 833/76\n",
            "[2024-08-08 09:35:38,944 INFO] Validation perplexity: 13.707\n",
            "[2024-08-08 09:35:38,944 INFO] Validation accuracy: 74.842\n",
            "[2024-08-08 09:35:38,944 INFO] Model is improving ppl: inf --> 13.707.\n",
            "[2024-08-08 09:35:38,944 INFO] Model is improving acc: -inf --> 74.842.\n",
            "[2024-08-08 09:35:38,955 INFO] Saving checkpoint models/model.tsongaeng_step_4000.pt\n",
            "[2024-08-08 09:36:13,356 INFO] Step 4100/ 6000; acc: 67.9; ppl:  17.2; xent: 2.8; lr: 0.00014; sents:   31355; bsz:  911/ 831/78; 3957/3610 tok/s;   1381 sec;\n",
            "[2024-08-08 09:36:40,486 INFO] Step 4200/ 6000; acc: 67.9; ppl:  17.2; xent: 2.8; lr: 0.00015; sents:   29621; bsz:  912/ 825/74; 13448/12158 tok/s;   1408 sec;\n",
            "[2024-08-08 09:37:07,753 INFO] Step 4300/ 6000; acc: 68.5; ppl:  16.8; xent: 2.8; lr: 0.00015; sents:   31362; bsz:  891/ 833/78; 13069/12224 tok/s;   1435 sec;\n",
            "[2024-08-08 09:37:13,828 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=1136)\n",
            "\n",
            "[2024-08-08 09:37:13,828 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2024-08-08 09:37:57,200 INFO] Step 4400/ 6000; acc: 71.9; ppl:  13.8; xent: 2.6; lr: 0.00016; sents:   29706; bsz:  909/ 843/74; 7352/6819 tok/s;   1484 sec;\n",
            "[2024-08-08 09:38:24,493 INFO] Step 4500/ 6000; acc: 71.2; ppl:  14.3; xent: 2.7; lr: 0.00016; sents:   33198; bsz:  888/ 831/83; 13013/12176 tok/s;   1512 sec;\n",
            "[2024-08-08 09:38:51,612 INFO] Step 4600/ 6000; acc: 71.1; ppl:  14.2; xent: 2.7; lr: 0.00016; sents:   30267; bsz:  920/ 837/76; 13575/12344 tok/s;   1539 sec;\n",
            "[2024-08-08 09:39:18,708 INFO] Step 4700/ 6000; acc: 71.1; ppl:  14.3; xent: 2.7; lr: 0.00017; sents:   29537; bsz:  910/ 833/74; 13429/12291 tok/s;   1566 sec;\n",
            "[2024-08-08 09:39:47,029 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=1153)\n",
            "\n",
            "[2024-08-08 09:39:47,030 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2024-08-08 09:40:06,159 INFO] Step 4800/ 6000; acc: 71.7; ppl:  13.9; xent: 2.6; lr: 0.00017; sents:   30333; bsz:  913/ 836/76; 7697/7051 tok/s;   1613 sec;\n",
            "[2024-08-08 09:40:33,382 INFO] Step 4900/ 6000; acc: 74.5; ppl:  12.0; xent: 2.5; lr: 0.00017; sents:   31600; bsz:  910/ 836/79; 13369/12281 tok/s;   1641 sec;\n",
            "[2024-08-08 09:41:00,615 INFO] Step 5000/ 6000; acc: 74.0; ppl:  12.3; xent: 2.5; lr: 0.00018; sents:   30296; bsz:  895/ 831/76; 13149/12211 tok/s;   1668 sec;\n",
            "[2024-08-08 09:41:00,628 INFO] Saving checkpoint models/model.tsongaeng_step_5000.pt\n",
            "[2024-08-08 09:41:35,468 INFO] Step 5100/ 6000; acc: 73.6; ppl:  12.5; xent: 2.5; lr: 0.00018; sents:   29691; bsz:  907/ 831/74; 10413/9535 tok/s;   1703 sec;\n",
            "[2024-08-08 09:42:03,013 INFO] Step 5200/ 6000; acc: 73.9; ppl:  12.3; xent: 2.5; lr: 0.00017; sents:   31585; bsz:  904/ 834/79; 13125/12114 tok/s;   1730 sec;\n",
            "[2024-08-08 09:42:53,370 INFO] Step 5300/ 6000; acc: 75.2; ppl:  11.5; xent: 2.4; lr: 0.00017; sents:   29467; bsz:  908/ 825/74; 7212/6551 tok/s;   1781 sec;\n",
            "[2024-08-08 09:43:20,705 INFO] Step 5400/ 6000; acc: 77.4; ppl:  10.4; xent: 2.3; lr: 0.00017; sents:   31268; bsz:  900/ 839/78; 13165/12283 tok/s;   1808 sec;\n",
            "[2024-08-08 09:43:48,256 INFO] Step 5500/ 6000; acc: 76.9; ppl:  10.6; xent: 2.4; lr: 0.00017; sents:   29283; bsz:  913/ 835/73; 13257/12124 tok/s;   1836 sec;\n",
            "[2024-08-08 09:44:15,515 INFO] Step 5600/ 6000; acc: 76.8; ppl:  10.7; xent: 2.4; lr: 0.00017; sents:   30306; bsz:  909/ 822/76; 13345/12065 tok/s;   1863 sec;\n",
            "[2024-08-08 09:44:42,605 INFO] Step 5700/ 6000; acc: 77.0; ppl:  10.6; xent: 2.4; lr: 0.00017; sents:   31221; bsz:  908/ 834/78; 13410/12315 tok/s;   1890 sec;\n",
            "[2024-08-08 09:44:52,450 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2323)\n",
            "\n",
            "[2024-08-08 09:44:52,450 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2024-08-08 09:45:30,034 INFO] Step 5800/ 6000; acc: 79.0; ppl:   9.7; xent: 2.3; lr: 0.00016; sents:   31247; bsz:  885/ 830/78; 7465/6996 tok/s;   1937 sec;\n",
            "[2024-08-08 09:45:57,438 INFO] Step 5900/ 6000; acc: 80.3; ppl:   9.1; xent: 2.2; lr: 0.00016; sents:   30656; bsz:  897/ 841/77; 13091/12274 tok/s;   1965 sec;\n",
            "[2024-08-08 09:46:24,839 INFO] Step 6000/ 6000; acc: 80.0; ppl:   9.2; xent: 2.2; lr: 0.00016; sents:   31834; bsz:  911/ 826/80; 13302/12061 tok/s;   1992 sec;\n",
            "[2024-08-08 09:46:24,852 INFO] Saving checkpoint models/model.tsongaeng_step_6000.pt\n"
          ]
        }
      ],
      "source": [
        " # Train the NMT model\n",
        "!onmt_train -config /content/config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YAiGm95n26m",
        "outputId": "a0c8850d-da1d-4209-d0f3-cdefb797cc7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-08 09:46:36,151 INFO] Loading checkpoint from /content/models/model.tsongaeng_step_6000.pt\n",
            "[2024-08-08 09:46:38,529 INFO] Loading data into the model\n",
            "[2024-08-08 09:50:06,643 INFO] PRED SCORE: -0.2737, PRED PPL: 1.31 NB SENTENCES: 3000\n",
            "Time w/o python interpreter load/terminate:  210.59305357933044\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model /content/models/model.tsongaeng_step_6000.pt -src /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Tsonga_Tsonga_test.txt.subword -output /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Ukuxhumana8heads.Translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoR5lT80oku7",
        "outputId": "a5337337-9187-48de-9116-b34ed5a95054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nmt\n",
            "Cloning into 'MT-Preparation'...\n",
            "remote: Enumerating objects: 290, done.\u001b[K\n",
            "remote: Counting objects: 100% (290/290), done.\u001b[K\n",
            "remote: Compressing objects: 100% (181/181), done.\u001b[K\n",
            "remote: Total 290 (delta 145), reused 189 (delta 97), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (290/290), 75.16 KiB | 1.47 MiB/s, done.\n",
            "Resolving deltas: 100% (145/145), done.\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p nmt\n",
        "%cd nmt\n",
        "!git clone https://github.com/ymoslem/MT-Preparation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T70zQfDhT0w",
        "outputId": "f2fa495f-a18d-4042-8d6f-a17af729b971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r MT-Preparation/requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r MT-Preparation/requirements.txt (line 2)) (2.1.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r MT-Preparation/requirements.txt (line 3)) (0.1.99)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r MT-Preparation/requirements.txt (line 2)) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install the requirements\n",
        "!pip3 install -r MT-Preparation/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb4ZQoyCo_uk",
        "outputId": "5ba1985b-921c-4315-e065-d1069f9a196f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd  ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZG2ry90pD-9",
        "outputId": "b571c15b-5267-4b04-8275-f57248393886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yaml  drive  models  nmt  run  sample_data  train.log\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMKppeeUpG7V",
        "outputId": "3dfc1e5c-c77b-4c81-c38e-61ffab587992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Ukuxhumana8heads.Translated.desubword\n"
          ]
        }
      ],
      "source": [
        "!python3 nmt/MT-Preparation/subwording/3-desubword.py /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/target.model /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Ukuxhumana8heads.Translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWDRrmQBpdBh",
        "outputId": "f7757142-2e12-466d-ec4f-744b4f24ce19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Tsonga_English_test.txt.subword.desubword\n"
          ]
        }
      ],
      "source": [
        "!python3 nmt/MT-Preparation/subwording/3-desubword.py /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/target.model /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Tsonga_English_test.txt.subword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63MKAmxep2zo",
        "outputId": "302181ca-bb9c-4762-e2f5-ab72c9a54d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-08 09:50:11--  https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 957 [text/plain]\n",
            "Saving to: ‘compute-bleu.py’\n",
            "\n",
            "compute-bleu.py     100%[===================>]     957  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-08 09:50:11 (87.2 MB/s) - ‘compute-bleu.py’ saved [957/957]\n",
            "\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.10.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n"
          ]
        }
      ],
      "source": [
        "# Download the BLEU script\n",
        "!wget https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
        "!pip3 install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG96qdHMp6Cw",
        "outputId": "7fd705f8-d192-4fe6-8597-21baff7738c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference 1st sentence: is the subject of children who are still children .\n",
            "MTed 1st sentence: on the subject of child soldiers .\n",
            "That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "BLEU:  61.065151685234504\n"
          ]
        }
      ],
      "source": [
        "!python3 compute-bleu.py /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Ukuxhumana8heads.Translated.desubword  /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Tsonga_English_test.txt.subword.desubword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZPeoiimQ84t",
        "outputId": "828a4d1d-3aa7-4942-c540-ee75af28ab6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-08 09:50:17,366 INFO] Loading checkpoint from /content/models/model.tsongaeng_step_6000.pt\n",
            "[2024-08-08 09:50:19,952 INFO] Loading data into the model\n",
            "[2024-08-08 09:55:35,846 INFO] PRED SCORE: -0.7940, PRED PPL: 2.21 NB SENTENCES: 1967\n",
            "Time w/o python interpreter load/terminate:  318.78488302230835\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model /content/models/model.tsongaeng_step_6000.pt -src /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/CCAligned.en-ts.txt.subword  -output /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/SyntheticEnglish.Translated"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 nmt/MT-Preparation/subwording/3-desubword.py /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/target.model /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/SyntheticEnglish.Translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ71w_P2Uuvx",
        "outputId": "3ce3b3b1-05dd-48b6-c80c-797f505259bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/SyntheticEnglish.Translated.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/SyntheticEnglish.Translated\n",
        "!wc -l /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/CCAligned.en-ts-en.txt.subword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d8H6xPrU6Ky",
        "outputId": "2d3a3094-08d6-4c1c-baf8-e77648780b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1967 /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/SyntheticEnglish.Translated\n",
            "1968 /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/CCAligned.en-ts-en.txt.subword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 compute-bleu.py /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/SyntheticEnglish.Translated /content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/CCAligned.en-ts-en.txt.subword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19DdI39bV5hg",
        "outputId": "76e08cd7-7d3a-4f03-9077-6c4f807137e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference 1st sentence: ▁To ▁ 1 ▁m .\n",
            "MTed 1st sentence: ▁Up ▁to ▁ 1 ▁m .\n",
            "That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "BLEU:  15.82008978978491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METEOR Score Computation"
      ],
      "metadata": {
        "id": "EK_LI5BGEp1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.meteor_score import meteor_score, single_meteor_score\n",
        "import nltk"
      ],
      "metadata": {
        "id": "M_HVvmt9W2Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to read the content of a text file\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Tokenize the text\n",
        "def tokenize(text):\n",
        "    return nltk.word_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa5kl_tev7vE",
        "outputId": "d1834955-12d8-4e79-e592-d838aa6d91c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read the content of a text file\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Paths to your text files\n",
        "file1_path = '/content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Ukuxhumana8heads.Translated.desubword'\n",
        "file2_path = '/content/drive/MyDrive/LanguageTranslationData_New/BackTranslation/TsongaEng/English_Tsonga_English_test.txt.subword.desubword'\n",
        "\n",
        "# Read the contents of the files\n",
        "reference = read_file(file1_path)\n",
        "hypothesis = read_file(file2_path)\n",
        "\n",
        "# Tokenize the texts\n",
        "reference_tokens = tokenize(reference)\n",
        "hypothesis_tokens = tokenize(hypothesis)\n",
        "\n",
        "# Calculate the METEOR score\n",
        "score = meteor_score([reference_tokens], hypothesis_tokens)\n",
        "\n",
        "print(f'The METEOR score between the two files is: {score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTJ-VlKwqXCX",
        "outputId": "cd9ca45a-3a50-4909-9d99-62a08345d199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The METEOR score between the two files is: 0.5650550587374646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1uHhoHhuLYO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}