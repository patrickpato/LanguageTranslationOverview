{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsFp4gutnEPZ",
        "outputId": "896e1c84-c552-4aa9-f0ba-75916dc4a9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUiZSmd-nw8S",
        "outputId": "bef636d1-3057-4a9d-c039-856f31cd8c66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-pil\n",
            "E: Unable to locate package python-lxml\n"
          ]
        }
      ],
      "source": [
        "!apt-get -y install protobuf-compiler python-pil python-lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLEFcu7tn5du",
        "outputId": "88e50e4d-9da7-4e05-c487-02d9742b2bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openNMT-py\n",
            "  Downloading OpenNMT_py-3.4.1-py3-none-any.whl (252 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/252.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m184.3/252.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<2.1,>=2.0 in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (2.0.1+cu118)\n",
            "Collecting configargparse (from openNMT-py)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ctranslate2<4,>=3.2 (from openNMT-py)\n",
            "  Downloading ctranslate2-3.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (2.13.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (2.2.5)\n",
            "Collecting waitress (from openNMT-py)\n",
            "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.35 (from openNMT-py)\n",
            "  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (6.0.1)\n",
            "Collecting sacrebleu (from openNMT-py)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from openNMT-py)\n",
            "  Downloading rapidfuzz-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from openNMT-py)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasttext-wheel (from openNMT-py)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.2->openNMT-py) (1.23.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (3.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (3.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (0.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->openNMT-py) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->openNMT-py) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->openNMT-py) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->openNMT-py) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->openNMT-py) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->openNMT-py) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0->openNMT-py) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0->openNMT-py) (17.0.2)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->openNMT-py)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->openNMT-py) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->openNMT-py) (8.1.7)\n",
            "Collecting portalocker (from sacrebleu->openNMT-py)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->openNMT-py) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->openNMT-py) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->openNMT-py)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->openNMT-py) (4.9.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (4.66.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (1.10.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->openNMT-py) (3.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->openNMT-py) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->openNMT-py) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->openNMT-py) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->openNMT-py) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=2.0->openNMT-py) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->openNMT-py) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->openNMT-py) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->openNMT-py) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->openNMT-py) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->openNMT-py) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->openNMT-py) (0.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=2.0->openNMT-py) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->openNMT-py) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->openNMT-py) (3.2.2)\n",
            "Installing collected packages: waitress, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, ctranslate2, configargparse, colorama, sacrebleu, fasttext-wheel, openNMT-py\n",
            "Successfully installed colorama-0.4.6 configargparse-1.7 ctranslate2-3.20.0 fasttext-wheel-0.9.2 openNMT-py-3.4.1 portalocker-2.8.2 pyahocorasick-2.0.0 pybind11-2.11.1 pyonmttok-1.37.1 rapidfuzz-3.4.0 sacrebleu-2.3.1 waitress-2.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openNMT-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-sDfaoRoKC8"
      },
      "outputs": [],
      "source": [
        "config = '''# config.yaml\n",
        "\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "# Training files\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/English_Luganda_Eng.txt.subword.train\n",
        "        path_tgt: /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/English_Luganda_Lug.txt.subword.train\n",
        "        transforms: [filtertoolong]\n",
        "    valid:\n",
        "        path_src: /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/English_Luganda_Eng.txt.subword.test\n",
        "        path_tgt: /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/English_Luganda_Lug.txt.subword.test\n",
        "        transforms: [filtertoolong]\n",
        "# Vocabulary files, generated by onmt_build_vocab\n",
        "src_vocab: run/source.vocab\n",
        "tgt_vocab: run/target.vocab\n",
        "\n",
        "# Vocabulary size - should be the same as in sentence piece\n",
        "#Benchmark value is 10k\n",
        "src_vocab_size: 50000\n",
        "tgt_vocab_size: 50000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 64\n",
        "tgt_seq_length: 64\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/source.model\n",
        "tgt_subword_model: /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/target.model\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/model.engluganda\n",
        "\n",
        "# Stop training if it does not imporve after n validations\n",
        "early_stopping: 10\n",
        "\n",
        "# Default: 5000 - Save a model checkpoint for each n\n",
        "save_checkpoint_steps: 1000\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "# keep_checkpoint: 3\n",
        "\n",
        "seed: 2023\n",
        "\n",
        "# Default: 100000 - Train the model to max n steps\n",
        "# Increase to 200000 or more for large datasets\n",
        "# For fine-tuning, add up the required steps to the original steps\n",
        "train_steps: 6000\n",
        "\n",
        "# Default: 10000 - Run validation after n steps\n",
        "valid_steps: 4000\n",
        "\n",
        "# Default: 4000 - for large datasets, try up to 8000\n",
        "warmup_steps: 5000\n",
        "report_every: 100\n",
        "\n",
        "# Number of GPUs, and IDs of GPUs\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Batching\n",
        "bucket_size: 262144\n",
        "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 1024  # Tokens per batch, change when CUDA out of memory\n",
        "valid_batch_size: 1024\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 0.4\n",
        "# warmup_steps: 8000\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 16\n",
        "dec_layers: 16\n",
        "heads: 16\n",
        "hidden_size: 1024\n",
        "word_vec_size: 1024\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "'''\n",
        "\n",
        "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lNRjFUyFMl9",
        "outputId": "01459241-e80b-4be4-f006-24d9b24e6f04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-14 16:08:09.994600: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-14 16:08:10.991699: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-14 16:08:12.357198: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-14 16:08:12.357688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-14 16:08:12.357870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2023-10-14 16:08:13,819 INFO] Counter vocab from -1 samples.\n",
            "[2023-10-14 16:08:13,819 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2023-10-14 16:08:16,303 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=16)\n",
            "\n",
            "[2023-10-14 16:08:16,381 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=10)\n",
            "\n",
            "[2023-10-14 16:08:16,437 INFO] Counters src: 21421\n",
            "[2023-10-14 16:08:16,438 INFO] Counters tgt: 40457\n"
          ]
        }
      ],
      "source": [
        "!onmt_build_vocab -config /content/config.yaml -n_sample -1 -num_threads 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFY_xrILFTPL",
        "outputId": "f53b9c45-02d2-431b-8672-e3ee5e122d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-14 16:08:21.036270: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-14 16:08:22.056739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-14 16:08:23.409311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-14 16:08:23.409769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-14 16:08:23.409936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2023-10-14 16:08:24,118 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2023-10-14 16:08:24,118 INFO] Parsed 2 corpora from -data.\n",
            "[2023-10-14 16:08:24,118 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2023-10-14 16:08:24,310 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '▁\"', '.\"', '▁the', '▁to', '.', '▁of']\n",
            "[2023-10-14 16:08:24,310 INFO] The decoder start token is: <s>\n",
            "[2023-10-14 16:08:24,311 INFO] Building model...\n",
            "[2023-10-14 16:08:28,495 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2023-10-14 16:08:28,495 INFO] Non quantized layer compute is fp16\n",
            "[2023-10-14 16:08:35,823 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(21432, 1024, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-15): 16 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=1024, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(40464, 1024, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-15): 16 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=1024, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=1024, out_features=40464, bias=True)\n",
            ")\n",
            "[2023-10-14 16:08:35,830 INFO] encoder: 156231680\n",
            "[2023-10-14 16:08:35,830 INFO] decoder: 284337680\n",
            "[2023-10-14 16:08:35,830 INFO] * number of parameters: 440569360\n",
            "[2023-10-14 16:08:35,832 INFO] Trainable parameters = {'torch.float32': 440569360, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2023-10-14 16:08:35,832 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2023-10-14 16:08:35,832 INFO]  * src vocab size = 21432\n",
            "[2023-10-14 16:08:35,832 INFO]  * tgt vocab size = 40464\n",
            "[2023-10-14 16:08:35,836 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2023-10-14 16:08:35,836 INFO] Starting training on GPU: [0]\n",
            "[2023-10-14 16:08:35,836 INFO] Start training loop and validate every 4000 steps...\n",
            "[2023-10-14 16:08:35,837 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=64, tgt_seq_length=64))\n",
            "[2023-10-14 16:08:37,112 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2023-10-14 16:08:38,293 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2023-10-14 16:08:39,554 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2023-10-14 16:08:40,347 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2023-10-14 16:08:41,734 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2023-10-14 16:08:43,282 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2023-10-14 16:10:32,716 INFO] Step 100/ 6000; acc: 6.5; ppl: 24725.4; xent: 10.1; lr: 0.00000; sents:   30941; bsz:  868/ 912/77; 2970/3122 tok/s;    117 sec;\n",
            "[2023-10-14 16:12:13,918 INFO] Step 200/ 6000; acc: 11.7; ppl: 11487.0; xent: 9.3; lr: 0.00001; sents:   30511; bsz:  865/ 912/76; 3419/3605 tok/s;    218 sec;\n",
            "[2023-10-14 16:13:54,895 INFO] Step 300/ 6000; acc: 15.2; ppl: 5466.9; xent: 8.6; lr: 0.00001; sents:   30134; bsz:  861/ 909/75; 3411/3601 tok/s;    319 sec;\n",
            "[2023-10-14 16:15:36,095 INFO] Step 400/ 6000; acc: 22.1; ppl: 2389.9; xent: 7.8; lr: 0.00001; sents:   30468; bsz:  869/ 904/76; 3435/3574 tok/s;    420 sec;\n",
            "[2023-10-14 16:17:17,194 INFO] Step 500/ 6000; acc: 25.4; ppl: 1303.7; xent: 7.2; lr: 0.00002; sents:   31508; bsz:  868/ 904/79; 3436/3577 tok/s;    521 sec;\n",
            "[2023-10-14 16:18:58,620 INFO] Step 600/ 6000; acc: 27.8; ppl: 949.9; xent: 6.9; lr: 0.00002; sents:   31136; bsz:  876/ 915/78; 3456/3607 tok/s;    623 sec;\n",
            "[2023-10-14 16:20:39,535 INFO] Step 700/ 6000; acc: 29.2; ppl: 772.5; xent: 6.6; lr: 0.00002; sents:   30434; bsz:  855/ 910/76; 3389/3606 tok/s;    724 sec;\n",
            "[2023-10-14 16:21:09,266 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=182)\n",
            "\n",
            "[2023-10-14 16:21:09,266 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2023-10-14 16:21:10,054 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2023-10-14 16:21:13,056 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2023-10-14 16:21:13,815 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2023-10-14 16:21:14,586 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2023-10-14 16:21:18,112 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2023-10-14 16:22:39,805 INFO] Step 800/ 6000; acc: 30.2; ppl: 661.6; xent: 6.5; lr: 0.00003; sents:   30493; bsz:  869/ 902/76; 2889/3001 tok/s;    844 sec;\n",
            "[2023-10-14 16:24:20,930 INFO] Step 900/ 6000; acc: 30.7; ppl: 575.6; xent: 6.4; lr: 0.00003; sents:   30667; bsz:  869/ 909/77; 3437/3596 tok/s;    945 sec;\n",
            "[2023-10-14 16:26:02,165 INFO] Step 1000/ 6000; acc: 31.1; ppl: 509.7; xent: 6.2; lr: 0.00004; sents:   30344; bsz:  869/ 912/76; 3433/3605 tok/s;   1046 sec;\n",
            "[2023-10-14 16:26:02,178 INFO] Saving checkpoint models/model.engluganda_step_1000.pt\n",
            "[2023-10-14 16:27:59,405 INFO] Step 1100/ 6000; acc: 32.2; ppl: 440.0; xent: 6.1; lr: 0.00004; sents:   30838; bsz:  863/ 909/77; 2945/3102 tok/s;   1164 sec;\n",
            "[2023-10-14 16:29:40,565 INFO] Step 1200/ 6000; acc: 33.0; ppl: 388.0; xent: 6.0; lr: 0.00004; sents:   30258; bsz:  864/ 909/76; 3414/3595 tok/s;   1265 sec;\n",
            "[2023-10-14 16:31:21,830 INFO] Step 1300/ 6000; acc: 34.4; ppl: 328.1; xent: 5.8; lr: 0.00005; sents:   31518; bsz:  861/ 907/79; 3403/3583 tok/s;   1366 sec;\n",
            "[2023-10-14 16:33:02,737 INFO] Step 1400/ 6000; acc: 34.9; ppl: 297.9; xent: 5.7; lr: 0.00005; sents:   30417; bsz:  861/ 908/76; 3413/3598 tok/s;   1467 sec;\n",
            "[2023-10-14 16:34:13,463 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=156)\n",
            "\n",
            "[2023-10-14 16:34:13,464 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2023-10-14 16:34:16,452 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2023-10-14 16:34:17,176 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2023-10-14 16:34:17,906 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2023-10-14 16:34:21,380 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2023-10-14 16:34:22,122 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "[2023-10-14 16:35:05,747 INFO] Step 1500/ 6000; acc: 36.4; ppl: 249.1; xent: 5.5; lr: 0.00005; sents:   31007; bsz:  865/ 912/78; 2813/2965 tok/s;   1590 sec;\n",
            "[2023-10-14 16:36:46,706 INFO] Step 1600/ 6000; acc: 37.9; ppl: 211.2; xent: 5.4; lr: 0.00006; sents:   31215; bsz:  877/ 904/78; 3473/3580 tok/s;   1691 sec;\n",
            "[2023-10-14 16:38:27,216 INFO] Step 1700/ 6000; acc: 38.9; ppl: 188.1; xent: 5.2; lr: 0.00006; sents:   30438; bsz:  851/ 904/76; 3388/3599 tok/s;   1791 sec;\n",
            "[2023-10-14 16:40:08,059 INFO] Step 1800/ 6000; acc: 40.7; ppl: 155.9; xent: 5.0; lr: 0.00006; sents:   30560; bsz:  858/ 917/76; 3404/3636 tok/s;   1892 sec;\n",
            "[2023-10-14 16:41:49,329 INFO] Step 1900/ 6000; acc: 42.3; ppl: 133.8; xent: 4.9; lr: 0.00007; sents:   30507; bsz:  863/ 915/76; 3407/3614 tok/s;   1993 sec;\n",
            "[2023-10-14 16:43:30,416 INFO] Step 2000/ 6000; acc: 44.2; ppl: 115.2; xent: 4.7; lr: 0.00007; sents:   30453; bsz:  867/ 908/76; 3431/3594 tok/s;   2095 sec;\n",
            "[2023-10-14 16:43:30,430 INFO] Saving checkpoint models/model.engluganda_step_2000.pt\n",
            "[2023-10-14 16:45:26,018 INFO] Step 2100/ 6000; acc: 46.6; ppl:  95.3; xent: 4.6; lr: 0.00007; sents:   31015; bsz:  865/ 904/78; 2993/3129 tok/s;   2210 sec;\n",
            "[2023-10-14 16:47:07,394 INFO] Step 2200/ 6000; acc: 48.9; ppl:  79.6; xent: 4.4; lr: 0.00008; sents:   31496; bsz:  871/ 908/79; 3435/3584 tok/s;   2312 sec;\n",
            "[2023-10-14 16:47:15,823 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=156)\n",
            "\n",
            "[2023-10-14 16:47:15,823 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2023-10-14 16:47:16,600 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2023-10-14 16:47:17,352 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 22\n",
            "[2023-10-14 16:47:18,103 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 23\n",
            "[2023-10-14 16:47:21,612 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 24\n",
            "[2023-10-14 16:47:22,345 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 25\n",
            "[2023-10-14 16:47:23,083 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 26\n",
            "[2023-10-14 16:49:09,296 INFO] Step 2300/ 6000; acc: 51.5; ppl:  63.5; xent: 4.2; lr: 0.00008; sents:   31153; bsz:  871/ 906/78; 2859/2973 tok/s;   2433 sec;\n",
            "[2023-10-14 16:50:50,353 INFO] Step 2400/ 6000; acc: 53.6; ppl:  53.8; xent: 4.0; lr: 0.00008; sents:   30183; bsz:  864/ 909/75; 3420/3597 tok/s;   2535 sec;\n",
            "[2023-10-14 16:52:31,603 INFO] Step 2500/ 6000; acc: 56.3; ppl:  45.2; xent: 3.8; lr: 0.00009; sents:   31034; bsz:  876/ 907/78; 3459/3585 tok/s;   2636 sec;\n",
            "[2023-10-14 16:54:12,577 INFO] Step 2600/ 6000; acc: 58.7; ppl:  38.0; xent: 3.6; lr: 0.00009; sents:   31140; bsz:  858/ 906/78; 3400/3590 tok/s;   2737 sec;\n",
            "[2023-10-14 16:55:53,647 INFO] Step 2700/ 6000; acc: 60.6; ppl:  33.5; xent: 3.5; lr: 0.00010; sents:   30907; bsz:  865/ 909/77; 3423/3598 tok/s;   2838 sec;\n",
            "[2023-10-14 16:57:34,565 INFO] Step 2800/ 6000; acc: 63.4; ppl:  27.7; xent: 3.3; lr: 0.00010; sents:   31117; bsz:  870/ 908/78; 3446/3597 tok/s;   2939 sec;\n",
            "[2023-10-14 16:59:15,421 INFO] Step 2900/ 6000; acc: 64.9; ppl:  25.2; xent: 3.2; lr: 0.00010; sents:   29944; bsz:  853/ 911/75; 3383/3612 tok/s;   3040 sec;\n",
            "[2023-10-14 16:59:51,736 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=182)\n",
            "\n",
            "[2023-10-14 16:59:51,736 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 27\n",
            "[2023-10-14 16:59:52,510 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 28\n",
            "[2023-10-14 16:59:53,281 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 29\n",
            "[2023-10-14 16:59:54,025 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 30\n",
            "[2023-10-14 16:59:57,580 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 31\n",
            "[2023-10-14 16:59:58,329 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 32\n",
            "[2023-10-14 17:01:17,496 INFO] Step 3000/ 6000; acc: 68.3; ppl:  20.7; xent: 3.0; lr: 0.00011; sents:   30557; bsz:  863/ 902/76; 2829/2955 tok/s;   3162 sec;\n",
            "[2023-10-14 17:01:17,511 INFO] Saving checkpoint models/model.engluganda_step_3000.pt\n",
            "[2023-10-14 17:03:12,951 INFO] Step 3100/ 6000; acc: 71.5; ppl:  17.3; xent: 2.8; lr: 0.00011; sents:   30595; bsz:  857/ 909/76; 2971/3149 tok/s;   3277 sec;\n",
            "[2023-10-14 17:04:54,039 INFO] Step 3200/ 6000; acc: 73.0; ppl:  16.0; xent: 2.8; lr: 0.00011; sents:   30650; bsz:  862/ 911/77; 3411/3604 tok/s;   3378 sec;\n",
            "[2023-10-14 17:06:35,344 INFO] Step 3300/ 6000; acc: 76.4; ppl:  13.5; xent: 2.6; lr: 0.00012; sents:   30512; bsz:  871/ 914/76; 3437/3607 tok/s;   3480 sec;\n",
            "[2023-10-14 17:08:16,406 INFO] Step 3400/ 6000; acc: 77.2; ppl:  13.3; xent: 2.6; lr: 0.00012; sents:   29922; bsz:  863/ 913/75; 3416/3612 tok/s;   3581 sec;\n",
            "[2023-10-14 17:09:57,886 INFO] Step 3500/ 6000; acc: 80.7; ppl:  11.1; xent: 2.4; lr: 0.00012; sents:   31497; bsz:  873/ 910/79; 3442/3589 tok/s;   3682 sec;\n",
            "[2023-10-14 17:11:39,173 INFO] Step 3600/ 6000; acc: 81.4; ppl:  11.1; xent: 2.4; lr: 0.00013; sents:   31678; bsz:  873/ 904/79; 3447/3569 tok/s;   3783 sec;\n",
            "[2023-10-14 17:12:56,404 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=156)\n",
            "\n",
            "[2023-10-14 17:12:56,404 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 33\n",
            "[2023-10-14 17:12:57,161 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 34\n",
            "[2023-10-14 17:12:57,914 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 35\n",
            "[2023-10-14 17:12:58,653 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 36\n",
            "[2023-10-14 17:13:02,161 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 37\n",
            "[2023-10-14 17:13:02,887 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 38\n",
            "[2023-10-14 17:13:40,771 INFO] Step 3700/ 6000; acc: 82.5; ppl:  10.7; xent: 2.4; lr: 0.00013; sents:   30112; bsz:  860/ 912/75; 2830/3000 tok/s;   3905 sec;\n",
            "[2023-10-14 17:15:22,175 INFO] Step 3800/ 6000; acc: 88.2; ppl:   8.3; xent: 2.1; lr: 0.00013; sents:   30659; bsz:  870/ 911/77; 3433/3594 tok/s;   4006 sec;\n",
            "[2023-10-14 17:17:03,468 INFO] Step 3900/ 6000; acc: 89.5; ppl:   7.8; xent: 2.1; lr: 0.00014; sents:   30832; bsz:  862/ 911/77; 3405/3598 tok/s;   4108 sec;\n",
            "[2023-10-14 17:18:44,562 INFO] Step 4000/ 6000; acc: 89.2; ppl:   8.0; xent: 2.1; lr: 0.00014; sents:   30308; bsz:  861/ 905/76; 3407/3583 tok/s;   4209 sec;\n",
            "[2023-10-14 17:18:58,489 INFO] valid stats calculation\n",
            "                           took: 13.923815250396729 s.\n",
            "[2023-10-14 17:18:58,491 INFO] Train perplexity: 120.931\n",
            "[2023-10-14 17:18:58,491 INFO] Train accuracy: 49.6837\n",
            "[2023-10-14 17:18:58,491 INFO] Sentences processed: 1.22916e+06\n",
            "[2023-10-14 17:18:58,491 INFO] Average bsz:  865/ 909/77\n",
            "[2023-10-14 17:18:58,491 INFO] Validation perplexity: 120.835\n",
            "[2023-10-14 17:18:58,491 INFO] Validation accuracy: 50.3385\n",
            "[2023-10-14 17:18:58,491 INFO] Model is improving ppl: inf --> 120.835.\n",
            "[2023-10-14 17:18:58,491 INFO] Model is improving acc: -inf --> 50.3385.\n",
            "[2023-10-14 17:18:58,504 INFO] Saving checkpoint models/model.engluganda_step_4000.pt\n",
            "[2023-10-14 17:20:53,742 INFO] Step 4100/ 6000; acc: 91.9; ppl:   7.0; xent: 1.9; lr: 0.00014; sents:   30850; bsz:  861/ 913/77; 2666/2829 tok/s;   4338 sec;\n",
            "[2023-10-14 17:22:35,194 INFO] Step 4200/ 6000; acc: 93.9; ppl:   6.4; xent: 1.8; lr: 0.00015; sents:   31397; bsz:  878/ 911/78; 3461/3591 tok/s;   4439 sec;\n",
            "[2023-10-14 17:24:16,046 INFO] Step 4300/ 6000; acc: 93.6; ppl:   6.5; xent: 1.9; lr: 0.00015; sents:   31283; bsz:  866/ 899/78; 3435/3567 tok/s;   4540 sec;\n",
            "[2023-10-14 17:25:57,096 INFO] Step 4400/ 6000; acc: 93.0; ppl:   6.7; xent: 1.9; lr: 0.00016; sents:   30385; bsz:  861/ 908/76; 3409/3595 tok/s;   4641 sec;\n",
            "[2023-10-14 17:26:12,626 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=156)\n",
            "\n",
            "[2023-10-14 17:26:12,626 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 39\n",
            "[2023-10-14 17:26:13,411 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 40\n",
            "[2023-10-14 17:26:14,166 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 41\n",
            "[2023-10-14 17:26:14,908 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 42\n",
            "[2023-10-14 17:26:18,412 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 43\n",
            "[2023-10-14 17:26:19,141 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 44\n",
            "[2023-10-14 17:26:19,895 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 45\n",
            "[2023-10-14 17:27:58,759 INFO] Step 4500/ 6000; acc: 95.3; ppl:   5.8; xent: 1.8; lr: 0.00016; sents:   30623; bsz:  860/ 909/77; 2829/2988 tok/s;   4763 sec;\n",
            "[2023-10-14 17:29:39,424 INFO] Step 4600/ 6000; acc: 93.9; ppl:   6.3; xent: 1.8; lr: 0.00016; sents:   30311; bsz:  849/ 908/76; 3372/3606 tok/s;   4864 sec;\n",
            "[2023-10-14 17:31:20,666 INFO] Step 4700/ 6000; acc: 94.7; ppl:   6.0; xent: 1.8; lr: 0.00017; sents:   30560; bsz:  871/ 904/76; 3441/3571 tok/s;   4965 sec;\n",
            "[2023-10-14 17:33:01,905 INFO] Step 4800/ 6000; acc: 95.7; ppl:   5.6; xent: 1.7; lr: 0.00017; sents:   31608; bsz:  874/ 903/79; 3455/3569 tok/s;   5066 sec;\n",
            "[2023-10-14 17:34:43,084 INFO] Step 4900/ 6000; acc: 95.1; ppl:   5.8; xent: 1.8; lr: 0.00017; sents:   30849; bsz:  862/ 917/77; 3406/3625 tok/s;   5167 sec;\n",
            "[2023-10-14 17:36:24,495 INFO] Step 5000/ 6000; acc: 96.0; ppl:   5.5; xent: 1.7; lr: 0.00018; sents:   30916; bsz:  869/ 911/77; 3430/3592 tok/s;   5269 sec;\n",
            "[2023-10-14 17:36:24,511 INFO] Saving checkpoint models/model.engluganda_step_5000.pt\n",
            "[2023-10-14 17:38:21,237 INFO] Step 5100/ 6000; acc: 96.3; ppl:   5.4; xent: 1.7; lr: 0.00018; sents:   30547; bsz:  867/ 913/76; 2969/3127 tok/s;   5385 sec;\n",
            "[2023-10-14 17:39:13,585 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=159)\n",
            "\n",
            "[2023-10-14 17:39:13,586 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 46\n",
            "[2023-10-14 17:39:14,330 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 47\n",
            "[2023-10-14 17:39:15,073 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 48\n",
            "[2023-10-14 17:39:15,819 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 49\n",
            "[2023-10-14 17:39:19,371 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 50\n",
            "[2023-10-14 17:39:20,097 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 51\n",
            "[2023-10-14 17:40:22,816 INFO] Step 5200/ 6000; acc: 96.0; ppl:   5.5; xent: 1.7; lr: 0.00017; sents:   31087; bsz:  864/ 902/78; 2844/2967 tok/s;   5507 sec;\n",
            "[2023-10-14 17:42:03,831 INFO] Step 5300/ 6000; acc: 97.2; ppl:   5.1; xent: 1.6; lr: 0.00017; sents:   30762; bsz:  877/ 908/77; 3471/3594 tok/s;   5608 sec;\n",
            "[2023-10-14 17:43:44,677 INFO] Step 5400/ 6000; acc: 97.2; ppl:   5.1; xent: 1.6; lr: 0.00017; sents:   31045; bsz:  866/ 912/78; 3437/3616 tok/s;   5709 sec;\n",
            "[2023-10-14 17:45:25,726 INFO] Step 5500/ 6000; acc: 96.6; ppl:   5.2; xent: 1.7; lr: 0.00017; sents:   30670; bsz:  869/ 912/77; 3442/3610 tok/s;   5810 sec;\n",
            "[2023-10-14 17:47:06,641 INFO] Step 5600/ 6000; acc: 96.6; ppl:   5.2; xent: 1.7; lr: 0.00017; sents:   31341; bsz:  864/ 904/78; 3424/3585 tok/s;   5911 sec;\n",
            "[2023-10-14 17:48:47,474 INFO] Step 5700/ 6000; acc: 97.3; ppl:   5.0; xent: 1.6; lr: 0.00017; sents:   30198; bsz:  862/ 912/75; 3420/3618 tok/s;   6012 sec;\n",
            "[2023-10-14 17:50:28,239 INFO] Step 5800/ 6000; acc: 96.7; ppl:   5.2; xent: 1.6; lr: 0.00016; sents:   30699; bsz:  858/ 903/77; 3406/3584 tok/s;   6112 sec;\n",
            "[2023-10-14 17:51:51,686 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=179)\n",
            "\n",
            "[2023-10-14 17:51:51,686 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 52\n",
            "[2023-10-14 17:51:52,444 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 53\n",
            "[2023-10-14 17:51:53,222 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 54\n",
            "[2023-10-14 17:51:56,740 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 55\n",
            "[2023-10-14 17:51:57,486 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 56\n",
            "[2023-10-14 17:51:58,226 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 57\n",
            "[2023-10-14 17:52:29,878 INFO] Step 5900/ 6000; acc: 97.1; ppl:   5.1; xent: 1.6; lr: 0.00016; sents:   30318; bsz:  864/ 910/76; 2842/2992 tok/s;   6234 sec;\n",
            "[2023-10-14 17:54:10,783 INFO] Step 6000/ 6000; acc: 98.2; ppl:   4.8; xent: 1.6; lr: 0.00016; sents:   30145; bsz:  864/ 908/75; 3426/3601 tok/s;   6335 sec;\n",
            "[2023-10-14 17:54:10,797 INFO] Saving checkpoint models/model.engluganda_step_6000.pt\n"
          ]
        }
      ],
      "source": [
        "# Train the NMT model\n",
        "!onmt_train -config /content/config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fx9_vrq0gC6a",
        "outputId": "48b382f1-a0fd-4155-bb01-bdc626787103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-14 17:54:35.274262: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-14 17:54:36.249150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-14 17:54:37.586558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-14 17:54:37.586960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-14 17:54:37.587104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2023-10-14 17:54:38,861 INFO] Loading checkpoint from /content/models/model.engluganda_step_6000.pt\n",
            "[2023-10-14 17:54:42,752 INFO] Loading data into the model\n",
            "[2023-10-14 18:02:47,066 INFO] PRED SCORE: -0.6391, PRED PPL: 1.89 NB SENTENCES: 1400\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model /content/models/model.engluganda_step_6000.pt -src /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/English_Luganda_Eng.txt.subword.dev -output /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/Luganda_TranslatedV11.translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9T70zQfDhT0w",
        "outputId": "58922c9d-ba3c-4f70-ca66-b876dab3e1fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/nmt\n",
            "Cloning into 'MT-Preparation'...\n",
            "remote: Enumerating objects: 248, done.\u001b[K\n",
            "remote: Counting objects: 100% (248/248), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 248 (delta 123), reused 193 (delta 97), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (248/248), 64.32 KiB | 12.86 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p nmt\n",
        "%cd nmt\n",
        "!git clone https://github.com/ymoslem/MT-Preparation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8g6so3PXh8Kc",
        "outputId": "fc112854-af3a-4a6f-84c3-3b87c276b3a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r MT-Preparation/requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r MT-Preparation/requirements.txt (line 2)) (1.5.3)\n",
            "Collecting sentencepiece (from -r MT-Preparation/requirements.txt (line 3))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->-r MT-Preparation/requirements.txt (line 2)) (1.16.0)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "# Install the requirements\n",
        "!pip3 install -r MT-Preparation/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "US7HA0aciCeP",
        "outputId": "9db961f1-5aab-4fd0-b4eb-ad729de04530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd  ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_mdE7WYWjN1_",
        "outputId": "2a163e6b-1361-43a7-eef1-c12190b12ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config.yaml  drive  models  nmt  run  sample_data  train.log\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j5UXPziljgVp",
        "outputId": "afc51e24-085e-4324-d308-e9f07b8eb1f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done desubwording! Output: /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/Luganda_TranslatedV11.translated.desubword\n"
          ]
        }
      ],
      "source": [
        "!python3 nmt/MT-Preparation/subwording/3-desubword.py /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/target.model  /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/Luganda_TranslatedV11.translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F3Nd2awcKKN-",
        "outputId": "eabed95d-0876-4a34-efc2-f38da9a44491"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config.yaml  drive  models  nmt  run  sample_data  train.log\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zHTXW0P3kw0K",
        "outputId": "6752d7b6-beca-4986-c01f-da9f6c150b9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done desubwording! Output: /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/English_Luganda_Lug.txt.subword.dev.desubword\n"
          ]
        }
      ],
      "source": [
        "!python3 nmt/MT-Preparation/subwording/3-desubword.py /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/target.model /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/English_Luganda_Lug.txt.subword.dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zcDtaHujn3P",
        "outputId": "d8f3606d-06a7-4f50-958c-d08e22d65d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-23 16:23:32--  https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 957 [text/plain]\n",
            "Saving to: ‘compute-bleu.py’\n",
            "\n",
            "\rcompute-bleu.py       0%[                    ]       0  --.-KB/s               \rcompute-bleu.py     100%[===================>]     957  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-23 16:23:32 (60.4 MB/s) - ‘compute-bleu.py’ saved [957/957]\n",
            "\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "# Download the BLEU script\n",
        "!wget https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
        "!pip3 install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cys-wvvakOmQ",
        "outputId": "8d502aaf-f49d-4a43-a6ff-250b67872469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reference 1st sentence: Abnoonyiboobubudamu balina ekifo ekirala kye bayita ewaabwe.\n",
            "MTed 1st sentence: Abanoonyiboobubudamu balina obuzibu ewaka okuva ewaka.\n",
            "BLEU:  20.297015608969556\n"
          ]
        }
      ],
      "source": [
        "!python3 compute-bleu.py /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/English_Luganda_Lug.txt.subword.dev.desubword /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/Luganda_TranslatedV11.translated.desubword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p9HsIvpmIve",
        "outputId": "28e38986-7c80-46a0-adaa-613ac698e8ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "20.2970,\n",
            "47.0204,\n",
            "75.5923\n",
            "]\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "cat /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/Luganda_TranslatedV11.translated.desubword | sacrebleu /content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/English_Luganda_Lug.txt.subword.dev.desubword -m bleu chrf ter -b -w 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METEOR Score Compmutation"
      ],
      "metadata": {
        "id": "1W5bjoIPJ5V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.meteor_score import meteor_score, single_meteor_score\n",
        "import nltk"
      ],
      "metadata": {
        "id": "OJBPI55XypTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to read the content of a text file\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Tokenize the text\n",
        "def tokenize(text):\n",
        "    return nltk.word_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psch9BlfJw1-",
        "outputId": "58ca116a-7c56-461c-f24c-75c60413661e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read the content of a text file\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Paths to your text files\n",
        "file1_path = '/content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/English_Luganda_Lug.txt.subword.dev.desubword'\n",
        "file2_path = '/content/drive/MyDrive/LanguageTranslationData_New/EngLuganda_Kimera_Benchmark/Luganda_TranslatedV11.translated.desubword'\n",
        "\n",
        "# Read the contents of the files\n",
        "reference = read_file(file1_path)\n",
        "hypothesis = read_file(file2_path)\n",
        "\n",
        "# Tokenize the texts\n",
        "reference_tokens = tokenize(reference)\n",
        "hypothesis_tokens = tokenize(hypothesis)\n",
        "\n",
        "# Calculate the METEOR score\n",
        "score = meteor_score([reference_tokens], hypothesis_tokens)\n",
        "\n",
        "print(f'The METEOR score between the two files is: {score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cS7uSeuJ3Z8",
        "outputId": "e1a9dc0e-6cca-48ca-a4c0-991571f2a22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The METEOR score between the two files is: 0.39789450317024894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZ07wkblKWx8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}