{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKKD2bzWRf31",
        "outputId": "a2e0a715-0af6-4f94-936e-25b81e8c26ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.meteor_score import meteor_score, single_meteor_score\n",
        "import nltk"
      ],
      "metadata": {
        "id": "zuH4TelV3JTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUiZSmd-nw8S",
        "outputId": "ddf546a3-b2c6-4d1f-b1ca-4464d94a2a0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-pil\n",
            "E: Unable to locate package python-lxml\n"
          ]
        }
      ],
      "source": [
        "!apt-get -y install protobuf-compiler python-pil python-lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLEFcu7tn5du",
        "outputId": "2c983614-236b-49e7-fbd0-fcea4697e8b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openNMT-py\n",
            "  Downloading OpenNMT_py-3.3-py3-none-any.whl (242 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/242.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.9/242.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<2.1,>=1.13 in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (2.0.1+cu118)\n",
            "Collecting configargparse (from openNMT-py)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ctranslate2<4,>=3.2 (from openNMT-py)\n",
            "  Downloading ctranslate2-3.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (2.12.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (2.2.5)\n",
            "Collecting waitress (from openNMT-py)\n",
            "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.35 (from openNMT-py)\n",
            "  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from openNMT-py) (6.0.1)\n",
            "Collecting sacrebleu (from openNMT-py)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from openNMT-py)\n",
            "  Downloading rapidfuzz-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from openNMT-py)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasttext-wheel (from openNMT-py)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.2->openNMT-py) (1.23.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (1.57.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (3.4.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (2.3.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->openNMT-py) (0.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->openNMT-py) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->openNMT-py) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->openNMT-py) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->openNMT-py) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->openNMT-py) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->openNMT-py) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=1.13->openNMT-py) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=1.13->openNMT-py) (16.0.6)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->openNMT-py)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->openNMT-py) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->openNMT-py) (8.1.6)\n",
            "Collecting portalocker (from sacrebleu->openNMT-py)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->openNMT-py) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->openNMT-py) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->openNMT-py)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->openNMT-py) (4.9.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->openNMT-py) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->openNMT-py) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->openNMT-py) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->openNMT-py) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->openNMT-py) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=1.13->openNMT-py) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->openNMT-py) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->openNMT-py) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->openNMT-py) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->openNMT-py) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=1.13->openNMT-py) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->openNMT-py) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->openNMT-py) (3.2.2)\n",
            "Installing collected packages: waitress, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, ctranslate2, configargparse, colorama, sacrebleu, fasttext-wheel, openNMT-py\n",
            "Successfully installed colorama-0.4.6 configargparse-1.7 ctranslate2-3.18.0 fasttext-wheel-0.9.2 openNMT-py-3.3 portalocker-2.7.0 pyahocorasick-2.0.0 pybind11-2.11.1 pyonmttok-1.37.1 rapidfuzz-3.2.0 sacrebleu-2.3.1 waitress-2.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openNMT-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3BPgqwFl9PH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-sDfaoRoKC8"
      },
      "outputs": [],
      "source": [
        "config = '''# config.yaml\n",
        "\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "# Training files\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/CCAligned.en-sn-en.txt.subword.train\n",
        "        path_tgt: /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/CCAligned.en-sn.txt.subword.train\n",
        "        transforms: [filtertoolong]\n",
        "    valid:\n",
        "        path_src: /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/CCAligned.en-sn-en.txt.subword.dev\n",
        "        path_tgt: /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/CCAligned.en-sn.txt.subword.dev\n",
        "        transforms: [filtertoolong]\n",
        "\n",
        "# Vocabulary files, generated by onmt_build_vocab\n",
        "src_vocab: run/source.vocab\n",
        "tgt_vocab: run/target.vocab\n",
        "\n",
        "# Vocabulary size - should be the same as in sentence piece\n",
        "src_vocab_size: 50000\n",
        "tgt_vocab_size: 50000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 64\n",
        "tgt_seq_length: 64\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/source.model\n",
        "tgt_subword_model: /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/target.model\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/model.engshona\n",
        "\n",
        "# Stop training if it does not imporve after n validations\n",
        "early_stopping: 10\n",
        "\n",
        "# Default: 5000 - Save a model checkpoint for each n\n",
        "save_checkpoint_steps: 1000\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "# keep_checkpoint: 3\n",
        "\n",
        "seed: 2023\n",
        "\n",
        "# Default: 100000 - Train the model to max n steps\n",
        "# Increase to 200000 or more for large datasets\n",
        "# For fine-tuning, add up the required steps to the original steps\n",
        "train_steps: 6000\n",
        "\n",
        "# Default: 10000 - Run validation after n steps\n",
        "valid_steps: 4000\n",
        "\n",
        "# Default: 4000 - for large datasets, try up to 8000\n",
        "warmup_steps: 5000\n",
        "report_every: 100\n",
        "\n",
        "# Number of GPUs, and IDs of GPUs\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Batching\n",
        "bucket_size: 262144\n",
        "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 1024  # Tokens per batch, change when CUDA out of memory\n",
        "valid_batch_size: 1024\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 0.4\n",
        "# warmup_steps: 8000\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 16\n",
        "dec_layers: 16\n",
        "heads: 16\n",
        "hidden_size: 1024\n",
        "word_vec_size: 1024\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "'''\n",
        "\n",
        "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lNRjFUyFMl9",
        "outputId": "9b8b4869-db98-4e59-87b6-fed11f99c18d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2023-08-19 16:26:26,873 INFO] Counter vocab from -1 samples.\n",
            "[2023-08-19 16:26:26,873 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2023-08-19 16:26:34,114 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2738)\n",
            "\n",
            "[2023-08-19 16:26:34,278 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2731)\n",
            "\n",
            "[2023-08-19 16:26:34,495 INFO] Counters src: 44634\n",
            "[2023-08-19 16:26:34,495 INFO] Counters tgt: 46189\n"
          ]
        }
      ],
      "source": [
        "!onmt_build_vocab -config /content/config.yaml -n_sample -1 -num_threads 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFY_xrILFTPL",
        "outputId": "cf3840e2-e727-4a98-a587-3d9e0334effb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-08-19 16:26:38,856 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2023-08-19 16:26:38,856 INFO] Parsed 2 corpora from -data.\n",
            "[2023-08-19 16:26:38,857 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2023-08-19 16:26:39,238 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', '.', '▁', '0', '▁the', '1']\n",
            "[2023-08-19 16:26:39,238 INFO] The decoder start token is: <s>\n",
            "[2023-08-19 16:26:39,239 INFO] Building model...\n",
            "[2023-08-19 16:26:44,743 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2023-08-19 16:26:44,744 INFO] Non quantized layer compute is fp16\n",
            "[2023-08-19 16:26:52,241 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(44640, 1024, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-15): 16 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=1024, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(46200, 1024, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-15): 16 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=1024, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=1024, out_features=46200, bias=True)\n",
            ")\n",
            "[2023-08-19 16:26:52,248 INFO] encoder: 179996672\n",
            "[2023-08-19 16:26:52,248 INFO] decoder: 296090744\n",
            "[2023-08-19 16:26:52,248 INFO] * number of parameters: 476087416\n",
            "[2023-08-19 16:26:52,250 INFO] Trainable parameters = {'torch.float32': 476087416, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2023-08-19 16:26:52,250 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2023-08-19 16:26:52,250 INFO]  * src vocab size = 44640\n",
            "[2023-08-19 16:26:52,250 INFO]  * tgt vocab size = 46200\n",
            "[2023-08-19 16:26:52,255 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2023-08-19 16:26:52,255 INFO] Starting training on GPU: [0]\n",
            "[2023-08-19 16:26:52,255 INFO] Start training loop and validate every 4000 steps...\n",
            "[2023-08-19 16:26:52,255 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=64, tgt_seq_length=64))\n",
            "[2023-08-19 16:26:55,379 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2023-08-19 16:26:58,793 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2023-08-19 16:27:03,513 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2023-08-19 16:27:06,599 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2023-08-19 16:29:13,221 INFO] Step 100/ 6000; acc: 3.9; ppl: 34266.8; xent: 10.4; lr: 0.00000; sents:   19347; bsz:  922/ 899/48; 2617/2551 tok/s;    141 sec;\n",
            "[2023-08-19 16:31:07,079 INFO] Step 200/ 6000; acc: 6.2; ppl: 20625.3; xent: 9.9; lr: 0.00001; sents:   18933; bsz:  925/ 899/47; 3250/3158 tok/s;    255 sec;\n",
            "[2023-08-19 16:33:02,500 INFO] Step 300/ 6000; acc: 7.9; ppl: 12667.5; xent: 9.4; lr: 0.00001; sents:   18544; bsz:  927/ 896/46; 3212/3105 tok/s;    370 sec;\n",
            "[2023-08-19 16:34:58,245 INFO] Step 400/ 6000; acc: 10.3; ppl: 6963.1; xent: 8.8; lr: 0.00001; sents:   19857; bsz:  923/ 894/50; 3189/3088 tok/s;    486 sec;\n",
            "[2023-08-19 16:36:53,698 INFO] Step 500/ 6000; acc: 11.8; ppl: 4193.7; xent: 8.3; lr: 0.00002; sents:   21446; bsz:  916/ 894/54; 3173/3096 tok/s;    601 sec;\n",
            "[2023-08-19 16:38:49,192 INFO] Step 600/ 6000; acc: 12.4; ppl: 3246.9; xent: 8.1; lr: 0.00002; sents:   19187; bsz:  925/ 897/48; 3203/3107 tok/s;    717 sec;\n",
            "[2023-08-19 16:40:44,527 INFO] Step 700/ 6000; acc: 13.8; ppl: 2737.6; xent: 7.9; lr: 0.00002; sents:   20042; bsz:  921/ 895/50; 3195/3104 tok/s;    832 sec;\n",
            "[2023-08-19 16:42:40,103 INFO] Step 800/ 6000; acc: 15.5; ppl: 2278.6; xent: 7.7; lr: 0.00003; sents:   19072; bsz:  925/ 896/48; 3200/3101 tok/s;    948 sec;\n",
            "[2023-08-19 16:44:35,626 INFO] Step 900/ 6000; acc: 16.2; ppl: 2109.9; xent: 7.7; lr: 0.00003; sents:   19615; bsz:  921/ 893/49; 3190/3092 tok/s;   1063 sec;\n",
            "[2023-08-19 16:46:30,949 INFO] Step 1000/ 6000; acc: 17.9; ppl: 1794.2; xent: 7.5; lr: 0.00004; sents:   20533; bsz:  917/ 896/51; 3180/3108 tok/s;   1179 sec;\n",
            "[2023-08-19 16:46:30,967 INFO] Saving checkpoint models/model.engshona_step_1000.pt\n",
            "[2023-08-19 16:49:06,096 INFO] Step 1100/ 6000; acc: 18.6; ppl: 1693.2; xent: 7.4; lr: 0.00004; sents:   19966; bsz:  922/ 894/50; 2376/2305 tok/s;   1334 sec;\n",
            "[2023-08-19 16:51:01,776 INFO] Step 1200/ 6000; acc: 19.0; ppl: 1561.3; xent: 7.4; lr: 0.00004; sents:   18339; bsz:  929/ 896/46; 3211/3100 tok/s;   1450 sec;\n",
            "[2023-08-19 16:51:20,232 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=21929)\n",
            "\n",
            "[2023-08-19 16:51:20,233 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2023-08-19 16:51:23,647 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2023-08-19 16:51:28,829 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2023-08-19 16:51:31,107 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2023-08-19 16:53:28,241 INFO] Step 1300/ 6000; acc: 20.9; ppl: 1294.1; xent: 7.2; lr: 0.00005; sents:   19863; bsz:  920/ 899/50; 2512/2455 tok/s;   1596 sec;\n",
            "[2023-08-19 16:55:24,661 INFO] Step 1400/ 6000; acc: 21.6; ppl: 1167.1; xent: 7.1; lr: 0.00005; sents:   20834; bsz:  918/ 892/52; 3156/3064 tok/s;   1712 sec;\n",
            "[2023-08-19 16:57:21,284 INFO] Step 1500/ 6000; acc: 22.0; ppl: 1090.0; xent: 7.0; lr: 0.00005; sents:   18279; bsz:  928/ 897/46; 3183/3076 tok/s;   1829 sec;\n",
            "[2023-08-19 16:59:17,834 INFO] Step 1600/ 6000; acc: 22.6; ppl: 967.4; xent: 6.9; lr: 0.00006; sents:   19168; bsz:  922/ 895/48; 3166/3073 tok/s;   1946 sec;\n",
            "[2023-08-19 17:01:14,854 INFO] Step 1700/ 6000; acc: 22.9; ppl: 910.3; xent: 6.8; lr: 0.00006; sents:   18452; bsz:  928/ 895/46; 3172/3060 tok/s;   2063 sec;\n",
            "[2023-08-19 17:03:11,444 INFO] Step 1800/ 6000; acc: 24.5; ppl: 741.9; xent: 6.6; lr: 0.00006; sents:   20069; bsz:  919/ 895/50; 3154/3071 tok/s;   2179 sec;\n",
            "[2023-08-19 17:05:08,299 INFO] Step 1900/ 6000; acc: 24.9; ppl: 678.7; xent: 6.5; lr: 0.00007; sents:   18552; bsz:  930/ 898/46; 3182/3074 tok/s;   2296 sec;\n",
            "[2023-08-19 17:07:04,982 INFO] Step 2000/ 6000; acc: 26.2; ppl: 592.8; xent: 6.4; lr: 0.00007; sents:   20025; bsz:  922/ 897/50; 3160/3075 tok/s;   2413 sec;\n",
            "[2023-08-19 17:07:05,001 INFO] Saving checkpoint models/model.engshona_step_2000.pt\n",
            "[2023-08-19 17:09:31,338 INFO] Step 2100/ 6000; acc: 26.5; ppl: 563.4; xent: 6.3; lr: 0.00007; sents:   18034; bsz:  929/ 897/45; 2538/2451 tok/s;   2559 sec;\n",
            "[2023-08-19 17:11:27,921 INFO] Step 2200/ 6000; acc: 27.8; ppl: 501.6; xent: 6.2; lr: 0.00008; sents:   20350; bsz:  919/ 895/51; 3154/3070 tok/s;   2676 sec;\n",
            "[2023-08-19 17:13:24,896 INFO] Step 2300/ 6000; acc: 29.3; ppl: 442.3; xent: 6.1; lr: 0.00008; sents:   21648; bsz:  915/ 894/54; 3128/3058 tok/s;   2793 sec;\n",
            "[2023-08-19 17:15:21,380 INFO] Step 2400/ 6000; acc: 31.1; ppl: 377.2; xent: 5.9; lr: 0.00008; sents:   19725; bsz:  922/ 896/49; 3168/3077 tok/s;   2909 sec;\n",
            "[2023-08-19 17:15:51,911 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=21954)\n",
            "\n",
            "[2023-08-19 17:15:51,912 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2023-08-19 17:15:57,033 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2023-08-19 17:15:59,062 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2023-08-19 17:16:04,130 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2023-08-19 17:17:48,260 INFO] Step 2500/ 6000; acc: 32.4; ppl: 327.4; xent: 5.8; lr: 0.00009; sents:   19103; bsz:  924/ 895/48; 2518/2438 tok/s;   3056 sec;\n",
            "[2023-08-19 17:19:44,384 INFO] Step 2600/ 6000; acc: 34.5; ppl: 269.8; xent: 5.6; lr: 0.00009; sents:   20419; bsz:  918/ 896/51; 3163/3086 tok/s;   3172 sec;\n",
            "[2023-08-19 17:21:41,009 INFO] Step 2700/ 6000; acc: 35.8; ppl: 247.8; xent: 5.5; lr: 0.00010; sents:   20542; bsz:  921/ 895/51; 3157/3070 tok/s;   3289 sec;\n",
            "[2023-08-19 17:23:37,653 INFO] Step 2800/ 6000; acc: 37.3; ppl: 219.5; xent: 5.4; lr: 0.00010; sents:   19458; bsz:  923/ 895/49; 3166/3071 tok/s;   3405 sec;\n",
            "[2023-08-19 17:25:34,562 INFO] Step 2900/ 6000; acc: 38.0; ppl: 200.9; xent: 5.3; lr: 0.00010; sents:   20201; bsz:  920/ 893/51; 3148/3056 tok/s;   3522 sec;\n",
            "[2023-08-19 17:27:31,296 INFO] Step 3000/ 6000; acc: 40.2; ppl: 170.0; xent: 5.1; lr: 0.00011; sents:   21243; bsz:  917/ 893/53; 3141/3061 tok/s;   3639 sec;\n",
            "[2023-08-19 17:27:31,317 INFO] Saving checkpoint models/model.engshona_step_3000.pt\n",
            "[2023-08-19 17:30:18,367 INFO] Step 3100/ 6000; acc: 41.0; ppl: 156.5; xent: 5.1; lr: 0.00011; sents:   18118; bsz:  930/ 898/45; 2227/2151 tok/s;   3806 sec;\n",
            "[2023-08-19 17:32:14,379 INFO] Step 3200/ 6000; acc: 43.4; ppl: 129.1; xent: 4.9; lr: 0.00011; sents:   18273; bsz:  926/ 902/46; 3192/3110 tok/s;   3922 sec;\n",
            "[2023-08-19 17:34:10,834 INFO] Step 3300/ 6000; acc: 44.8; ppl: 116.0; xent: 4.8; lr: 0.00012; sents:   18319; bsz:  927/ 897/46; 3184/3081 tok/s;   4039 sec;\n",
            "[2023-08-19 17:36:07,741 INFO] Step 3400/ 6000; acc: 45.8; ppl: 105.6; xent: 4.7; lr: 0.00012; sents:   19345; bsz:  925/ 895/48; 3164/3062 tok/s;   4155 sec;\n",
            "[2023-08-19 17:38:04,551 INFO] Step 3500/ 6000; acc: 47.5; ppl:  92.6; xent: 4.5; lr: 0.00012; sents:   18413; bsz:  930/ 896/46; 3184/3069 tok/s;   4272 sec;\n",
            "[2023-08-19 17:40:01,299 INFO] Step 3600/ 6000; acc: 49.6; ppl:  79.3; xent: 4.4; lr: 0.00013; sents:   20335; bsz:  920/ 896/51; 3152/3070 tok/s;   4389 sec;\n",
            "[2023-08-19 17:40:46,964 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=21985)\n",
            "\n",
            "[2023-08-19 17:40:46,965 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2023-08-19 17:40:49,126 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2023-08-19 17:40:54,603 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2023-08-19 17:41:00,120 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2023-08-19 17:42:26,337 INFO] Step 3700/ 6000; acc: 52.6; ppl:  61.4; xent: 4.1; lr: 0.00013; sents:   20428; bsz:  920/ 894/51; 2537/2465 tok/s;   4534 sec;\n",
            "[2023-08-19 17:44:23,081 INFO] Step 3800/ 6000; acc: 54.6; ppl:  53.1; xent: 4.0; lr: 0.00013; sents:   18423; bsz:  928/ 898/46; 3180/3076 tok/s;   4651 sec;\n",
            "[2023-08-19 17:46:20,198 INFO] Step 3900/ 6000; acc: 55.6; ppl:  49.5; xent: 3.9; lr: 0.00014; sents:   19606; bsz:  923/ 894/49; 3154/3054 tok/s;   4768 sec;\n",
            "[2023-08-19 17:48:17,157 INFO] Step 4000/ 6000; acc: 57.7; ppl:  43.3; xent: 3.8; lr: 0.00014; sents:   21477; bsz:  915/ 895/54; 3130/3060 tok/s;   4885 sec;\n",
            "[2023-08-19 17:48:42,657 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 25.4951913356781 s.\n",
            "[2023-08-19 17:48:42,660 INFO] Train perplexity: 608.104\n",
            "[2023-08-19 17:48:42,661 INFO] Train accuracy: 29.1086\n",
            "[2023-08-19 17:48:42,661 INFO] Sentences processed: 783583\n",
            "[2023-08-19 17:48:42,661 INFO] Average bsz:  923/ 896/49\n",
            "[2023-08-19 17:48:42,661 INFO] Validation perplexity: 212.54\n",
            "[2023-08-19 17:48:42,661 INFO] Validation accuracy: 43.7753\n",
            "[2023-08-19 17:48:42,661 INFO] Model is improving ppl: inf --> 212.54.\n",
            "[2023-08-19 17:48:42,661 INFO] Model is improving acc: -inf --> 43.7753.\n",
            "[2023-08-19 17:48:42,680 INFO] Saving checkpoint models/model.engshona_step_4000.pt\n",
            "[2023-08-19 17:51:24,422 INFO] Step 4100/ 6000; acc: 58.7; ppl:  40.5; xent: 3.7; lr: 0.00014; sents:   19561; bsz:  924/ 897/49; 1974/1915 tok/s;   5072 sec;\n",
            "[2023-08-19 17:53:20,823 INFO] Step 4200/ 6000; acc: 59.8; ppl:  37.1; xent: 3.6; lr: 0.00015; sents:   19638; bsz:  924/ 896/49; 3176/3078 tok/s;   5189 sec;\n",
            "[2023-08-19 17:55:17,674 INFO] Step 4300/ 6000; acc: 61.1; ppl:  34.2; xent: 3.5; lr: 0.00015; sents:   20272; bsz:  920/ 891/51; 3148/3052 tok/s;   5305 sec;\n",
            "[2023-08-19 17:57:14,480 INFO] Step 4400/ 6000; acc: 63.0; ppl:  30.5; xent: 3.4; lr: 0.00016; sents:   20682; bsz:  916/ 895/52; 3138/3064 tok/s;   5422 sec;\n",
            "[2023-08-19 17:59:11,548 INFO] Step 4500/ 6000; acc: 63.9; ppl:  28.7; xent: 3.4; lr: 0.00016; sents:   19300; bsz:  924/ 897/48; 3158/3065 tok/s;   5539 sec;\n",
            "[2023-08-19 18:01:08,673 INFO] Step 4600/ 6000; acc: 64.8; ppl:  26.7; xent: 3.3; lr: 0.00016; sents:   18378; bsz:  930/ 894/46; 3176/3053 tok/s;   5656 sec;\n",
            "[2023-08-19 18:03:05,811 INFO] Step 4700/ 6000; acc: 66.3; ppl:  24.5; xent: 3.2; lr: 0.00017; sents:   19384; bsz:  923/ 896/48; 3152/3061 tok/s;   5774 sec;\n",
            "[2023-08-19 18:05:02,507 INFO] Step 4800/ 6000; acc: 68.7; ppl:  21.3; xent: 3.1; lr: 0.00017; sents:   19754; bsz:  920/ 897/49; 3154/3073 tok/s;   5890 sec;\n",
            "[2023-08-19 18:06:04,819 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=21977)\n",
            "\n",
            "[2023-08-19 18:06:04,820 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2023-08-19 18:06:07,962 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "[2023-08-19 18:06:13,127 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2023-08-19 18:06:19,432 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2023-08-19 18:07:31,714 INFO] Step 4900/ 6000; acc: 72.1; ppl:  17.6; xent: 2.9; lr: 0.00017; sents:   18639; bsz:  927/ 901/47; 2484/2416 tok/s;   6039 sec;\n",
            "[2023-08-19 18:09:27,782 INFO] Step 5000/ 6000; acc: 74.5; ppl:  15.6; xent: 2.7; lr: 0.00018; sents:   19837; bsz:  921/ 896/50; 3173/3089 tok/s;   6156 sec;\n",
            "[2023-08-19 18:09:27,804 INFO] Saving checkpoint models/model.engshona_step_5000.pt\n",
            "[2023-08-19 18:12:15,051 INFO] Step 5100/ 6000; acc: 75.0; ppl:  15.1; xent: 2.7; lr: 0.00018; sents:   18040; bsz:  931/ 897/45; 2226/2144 tok/s;   6323 sec;\n",
            "[2023-08-19 18:14:10,808 INFO] Step 5200/ 6000; acc: 76.7; ppl:  14.0; xent: 2.6; lr: 0.00017; sents:   20574; bsz:  918/ 896/51; 3171/3095 tok/s;   6439 sec;\n",
            "[2023-08-19 18:16:07,790 INFO] Step 5300/ 6000; acc: 76.9; ppl:  13.8; xent: 2.6; lr: 0.00017; sents:   18633; bsz:  926/ 893/47; 3167/3055 tok/s;   6556 sec;\n",
            "[2023-08-19 18:18:04,528 INFO] Step 5400/ 6000; acc: 78.2; ppl:  13.0; xent: 2.6; lr: 0.00017; sents:   19930; bsz:  921/ 897/50; 3157/3072 tok/s;   6672 sec;\n",
            "[2023-08-19 18:20:01,117 INFO] Step 5500/ 6000; acc: 79.3; ppl:  12.3; xent: 2.5; lr: 0.00017; sents:   20078; bsz:  920/ 895/50; 3158/3070 tok/s;   6789 sec;\n",
            "[2023-08-19 18:21:57,911 INFO] Step 5600/ 6000; acc: 80.0; ppl:  11.9; xent: 2.5; lr: 0.00017; sents:   20845; bsz:  920/ 891/52; 3150/3052 tok/s;   6906 sec;\n",
            "[2023-08-19 18:23:54,410 INFO] Step 5700/ 6000; acc: 81.8; ppl:  10.9; xent: 2.4; lr: 0.00017; sents:   19361; bsz:  924/ 896/48; 3174/3076 tok/s;   7022 sec;\n",
            "[2023-08-19 18:25:51,232 INFO] Step 5800/ 6000; acc: 83.2; ppl:  10.2; xent: 2.3; lr: 0.00016; sents:   20242; bsz:  920/ 897/51; 3151/3071 tok/s;   7139 sec;\n",
            "[2023-08-19 18:27:47,799 INFO] Step 5900/ 6000; acc: 84.6; ppl:   9.5; xent: 2.3; lr: 0.00016; sents:   19164; bsz:  924/ 894/48; 3170/3069 tok/s;   7256 sec;\n",
            "[2023-08-19 18:29:44,484 INFO] Step 6000/ 6000; acc: 85.1; ppl:   9.3; xent: 2.2; lr: 0.00016; sents:   18923; bsz:  923/ 898/47; 3166/3078 tok/s;   7372 sec;\n",
            "[2023-08-19 18:29:44,506 INFO] Saving checkpoint models/model.engshona_step_6000.pt\n"
          ]
        }
      ],
      "source": [
        " # Train the NMT model\n",
        "!onmt_train -config /content/config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fx9_vrq0gC6a",
        "outputId": "88d1181a-5b3d-40e8-a32b-45bd7ce30b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-08-19 18:30:37,409 INFO] Loading checkpoint from /content/models/model.engshona_step_6000.pt\n",
            "[2023-08-19 18:31:00,243 INFO] Loading data into the model\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt_translate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/translate.py\", line 56, in main\n",
            "    translate(opt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/translate.py\", line 37, in translate\n",
            "    _, _ = translator._translate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/onmt/translate/translator.py\", line 441, in _translate\n",
            "    self.out_file.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model /content/models/model.engshona_step_6000.pt -src /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/CCAligned.en-sn-en.txt.subword.test -output /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/ShonaV9.translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9T70zQfDhT0w",
        "outputId": "d9aa8b51-4aa1-4aa4-8721-99fb2b951d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/nmt\n",
            "Cloning into 'MT-Preparation'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
            "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
            "remote: Total 239 (delta 119), reused 186 (delta 94), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (239/239), 61.56 KiB | 4.74 MiB/s, done.\n",
            "Resolving deltas: 100% (119/119), done.\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p nmt\n",
        "%cd nmt\n",
        "!git clone https://github.com/ymoslem/MT-Preparation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g6so3PXh8Kc"
      },
      "outputs": [],
      "source": [
        "# Install the requirements\n",
        "!pip3 install -r MT-Preparation/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US7HA0aciCeP"
      },
      "outputs": [],
      "source": [
        "%cd  ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mdE7WYWjN1_"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5UXPziljgVp"
      },
      "outputs": [],
      "source": [
        "!python3 nmt/MT-Preparation/subwording/3-desubword.py /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/target.model /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/ShonaV9.translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHTXW0P3kw0K"
      },
      "outputs": [],
      "source": [
        "!python3 nmt/MT-Preparation/subwording/3-desubword.py /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/target.model /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/CCAligned.en-sn.txt.subword.test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zcDtaHujn3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a3cd97-29f1-4ece-a381-5bd712b04aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-29 16:41:28--  https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 957 [text/plain]\n",
            "Saving to: ‘compute-bleu.py’\n",
            "\n",
            "compute-bleu.py     100%[===================>]     957  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-29 16:41:28 (44.3 MB/s) - ‘compute-bleu.py’ saved [957/957]\n",
            "\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Download the BLEU script\n",
        "!wget https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
        "!pip3 install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cys-wvvakOmQ",
        "outputId": "c50e1bec-eddb-4497-8c31-1675fdbf3113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reference 1st sentence: Akatswiri Amagetsi\n",
            "MTed 1st sentence: Sarudza Mutauro\n",
            "BLEU:  22.04878620393455\n"
          ]
        }
      ],
      "source": [
        "!python3 compute-bleu.py /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/CCAligned.en-sn.txt.subword.test.desubword /content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/ShonaV9.translated.desubword"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to read the content of a text file\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Tokenize the text\n",
        "def tokenize(text):\n",
        "    return nltk.word_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8J9eTXG3cel",
        "outputId": "fdb72c70-e3e7-4f7c-fa5b-7a873c4e531a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read the content of a text file\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Paths to your text files\n",
        "file1_path = '/content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/ShonaV9.translated.desubword'\n",
        "file2_path = '/content/drive/MyDrive/LanguageTranslationData_New/EnglishShona_DataPrep_SentencePieceModel/CCAligned.en-sn.txt.subword.test.desubword'\n",
        "\n",
        "# Read the contents of the files\n",
        "reference = read_file(file1_path)\n",
        "hypothesis = read_file(file2_path)\n",
        "\n",
        "# Tokenize the texts\n",
        "reference_tokens = tokenize(reference)\n",
        "hypothesis_tokens = tokenize(hypothesis)\n",
        "\n",
        "# Calculate the METEOR score\n",
        "score = meteor_score([reference_tokens], hypothesis_tokens)\n",
        "\n",
        "print(f'The METEOR score between the two files is: {score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXStWvpT3cdB",
        "outputId": "0400ea2a-9e0f-41fc-8945-b118b57615bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The METEOR score between the two files is: 0.2680294255395139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Observed inconsistency between the number of lines in the two files being compared.\n",
        "#To check if the inconsistency is responsible for the declining METEOR score."
      ],
      "metadata": {
        "id": "kqQK_evV1llU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4dXhq325BMh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}